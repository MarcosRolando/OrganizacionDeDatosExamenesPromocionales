2) Considerar los siguientes puntos en una dimensión y la clase a la que
pertenece cada punto:

5-b, 10-b, 2-b, 6-a,

7-b, 8-b, 0-a, 13-b,

16-b, 1-a, 3-a, 17-b

(el número es
el valor de x, la letra es la clase a la que pertenece)
Se quiere usar KNN para clasificar los puntos con la distancia
Manhattan.
A fin de encontrar el valor óptimo de k (cantidad de vecinos) se decide
usar cross-validation con folds de 4 registros,
considerar los folds en el orden en que fueron presentados los puntos,
es decir que el primer fold tiene (5-b,10-b,2-b,6-a).
Determinar el valor óptimo de "k" realizando grid-search para tres
valores posiblesde k: 1,3 y 5. Usar precisión (accuracy) como métrica.
(15 pts) (***)

Respuesta:

IMPORTANTE: no sabemos bien que pasa si el punto esta a igual distancia de 2 o mas
valores que tienen distintas predicciones cada una. Para mantener consistencia
decidimos que en dicho caso el algoritmo se quedara con el menor valor absoluto (
ej entre 6 y 8 se queda con el 6)

Tenemos 3 folds en total (cada fold tiene 4 regitros) donde el metodo de K-folds
se guarda entrena k veces con k - 1 folds y utiliza el fold restante para validar,
dicho fold cambia en cada iteracion a uno que no haya sido utilizado previamente.

Entonces tendriamos que

            Acc(k=1)    Acc(k=3)    Acc(k=5)

fold 1      0.5         0.5         0.5

fold 2      0.5         1           1

fold 3      0.75        0.25        0.5

Si promedios las 3 columnas vemos trivialmente que k = 5 da el mejor resultado.