1) Estamos construyendo un árbol de decisión para clasificar si un
conjunto de platos es adecuado para carnívoros (clase C) o veganos
(clase V). Para un cierto split el algoritmo CART debe analizar si hacer
o no un split por la columna “ingrediente 2 en gramos” que es una
columna numérica. Dados los valores de la columna y la clase a
predecir le pedimos que indique cuál sería el valor de la ganancia de
información para la columna en cuestión.

23, V
80, C
85, C
65, V
100, V
11, C

(15 pts)

Respuesta:

Calculamos la entropia de del sistema, donde la formula de la entropia es

H(X) = - sum(Pi*log2(Pi), i, , n) con n la cantidad de datos distintos

H(3/6, 3/6) = 1

Ahora ordenamos los target en base a la columna numerica

CVVCCV

Donde tenemos los siguientes splits posibles

a) C VVCCV

b) CV VCCV

c) CVV CCV

d) CVVC CV

e) CVVCC V

Calculamos la entropia de cada split, obteniendo

a) 1/6*H(1/1, 0/1) + 5/6*H(2/5, 3/5) = 0.809
b) 2/6*H(1/2, 1/2) + 4/6*H(2/4, 2/4) = 1
c) 3/6*H(1/3, 2/3) + 3/6*H(2/3, 1/3) = 0.918
d) 4/6*H(2/4, 2/4) + 2/6*H(1/2, 1/2) = 1
e) 5/6*H(3/5, 2/5) + 1/6*H(0/1, 1/1) = 0.809

Luego la ganancia de informacion es la entropia del sistema menos la entropia
del split, y lo que queremos es que esa ganancia sea maxima, por lo tanto nos
queremos quedar con la entropia del split minima. Finalmente la ganancia
de informacion seria 1 - 0.809 = 0.191 (no se si te quedas con a o e o da igual
pero el ejercicio solo pide el valor de la gananica).