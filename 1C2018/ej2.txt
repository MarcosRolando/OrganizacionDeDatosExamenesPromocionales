a. Armar un árbol de decisión seleccionando en cada split el atributo que mayor ganancia de
información nos da. (8pts)
b. Explicar cómo hacer para evitar el overfitting y aplicarlo al árbol del punto anterior. (**) (7 pts)

IMPORTANTE: ver grafico de la tabla en ej2.png

Respuesta:

a)

Que ejercicio paja. PERO BIEN PAJA EH. Bueno, primero calculamos la entropia
del set.

H(X) = -sum(Pi*log2(Pi), i, 1, n) donde n es la cantidad de targets

entonces

H(SET) = - (1/2*log2(1/2)*2) = 1

Ahora debemos calcular la entropia de cada columna (excepto la de persona
porque esa es solo la entrada, no es un atributo) donde tendriamos que

H(Estudios) = -(1/2*log2(1/2) + 1/4*log2(1/4) + 1/4*log2(1/4)) = 1.5
H(Trabaja?) = -(3/4*log2(3/4) + 1/4*log2(1/4)) = 0.8113
H(Estado Civil) = -(1/3*log2(1/3) + 1/3*log2(1/3) + 1/3*log2(1/3)) = 1.585

Entonces sabiendo que la ganancia se calcular restando la entropia de la columna
a la entropia del sistema obtendremos la mayor ganancia cuando la entropia de la
columna sea minima, por lo que debemos hacer los split en partiendo desde la columna
de menor entropia. Entonces vemos que el primer split lo hacemos por la columna Trabaja?.

Ahora calculamos lo mismo para los datos que tienen campo SI en Trabaja?

H(Estudios) = -(5/9*log2(5/9) + 1/3*log2(1/3) + 1/9*log2(1/9)) = 1.3516
H(Estado Civil) = -(1/3*log2(1/3) + 4/9*log2(4/9) + 2/9*log2(2/9)) = 1.53

Entonces haremos el split por Estudios (recordemos que estamos en el caso
que si trabaja). Para Primarios tenemos que hacer un split por estado Civil
(ya que no es hoja) y ver que predicciones hay para cada caso. Para universitarios
tambien porque tampoco es hoja. Y ya tremenda paja de explicar el de Secundarios pero es
lo mismo.

Ahora para el caso donde Trabaja? sea NO tenemos que todas las predicciones son NO,
por lo tanto no haremos otro split ahi.

Para resumir todo este bardo, ver el grafico de ej2a.jpg

b)

Para disminuir el overfitting lo que podemos utilizar es mean buckets,
el cual dice que dado un valor k de buckets si nuestro nodo tiene menos de
k registros entonces no hacemos un split sino que directamente vemos de guardarnos
la prediccion del valor que mas aparezca (o la probabilidad de las clases, como
prefieras armar el modelo). Paja de aplicarlo al arbol, pero ponele que podrias elegir
k = 4 entonces no harias los splits si tenes menos de 4 registros en alguno de los nodos
(que creo que teniamos algunos nodos con menos de 4 pero paja de fijarme).
